
# ğŸ§  InterviewFlow â€” DocumentaÃ§Ã£o TÃ©cnica

## ğŸ“‹ VisÃ£o Geral

**InterviewFlow** Ã© uma aplicaÃ§Ã£o full-stack em **Next.js (App Router)** com **rotas serverless** integradas Ã  **API da OpenAI**, criada para automatizar a transcriÃ§Ã£o, anÃ¡lise e sumarizaÃ§Ã£o de entrevistas.

O objetivo Ã© permitir a **conduÃ§Ã£o de entrevistas com pauta parametrizÃ¡vel**, marcando automaticamente os temas abordados e gerando um **resumo final estruturado** (ata).

---

## âš™ï¸ Stack TÃ©cnica

| Camada              | Tecnologia                                |
| ------------------- | ----------------------------------------- |
| Frontend            | Next.js 15 (App Router, React 18)         |
| Estilo              | TailwindCSS                               |
| Ãudio               | MediaRecorder API                         |
| Backend             | Serverless Functions (API Routes Next.js) |
| IA                  | OpenAI GPT-4o-mini + Whisper              |
| Armazenamento Local | `localStorage` (browser)                  |
| Deploy              | Vercel                                    |

---

## ğŸ—ï¸ Estrutura de Pastas

```
app/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ analyze/
â”‚   â”‚   â””â”€â”€ route.js       â†’ Marca pautas/subpautas completas
â”‚   â”œâ”€â”€ summarize/
â”‚   â”‚   â””â”€â”€ route.js       â†’ Gera ata e resumo final
â”‚   â”œâ”€â”€ transcribe/
â”‚   â”‚   â””â”€â”€ route.js       â†’ Transcreve Ã¡udio (Whisper)
â”‚   â””â”€â”€ test/
â”‚       â””â”€â”€ route.js       â†’ Endpoint opcional de debug
â”‚
â”œâ”€â”€ interview/
â”‚   â””â”€â”€ page.js            â†’ LÃ³gica principal da entrevista
â”‚
â”œâ”€â”€ page.js                â†’ Tela inicial (criaÃ§Ã£o e gerenciamento de pautas)
â”œâ”€â”€ layout.js              â†’ Layout global da aplicaÃ§Ã£o
â””â”€â”€ globals.css            â†’ Estilos base e tema
```

---

## ğŸ”‘ VariÃ¡veis de Ambiente

Arquivo `.env.local`:

```bash
OPENAI_API_KEY=sk-xxxxx
```

Na Vercel:

```
Settings â†’ Environment Variables â†’ OPENAI_API_KEY
```

---

## ğŸ§© Fluxo LÃ³gico (Resumido)

### 1ï¸âƒ£ CriaÃ§Ã£o de Pautas (`/page.js`)

* UsuÃ¡rio define o **tipo de pauta** (ex: â€œEntrevista de Acolhimentoâ€);
* Cria pautas e subpautas manualmente;
* Pode salvar modelos em `localStorage` (`modelosPautas`);
* Pode carregar e sobrescrever modelos existentes;
* Ao clicar em â€œIniciar Entrevistaâ€, o app salva:

  ```json
  { "tipo": "Acolhimento", "pautas": [...] }
  ```

  em `localStorage` (`pautasAtuais`) e redireciona para `/interview`.

---

### 2ï¸âƒ£ Entrevista em Andamento (`/interview/page.js`)

#### ğŸ”¹ InÃ­cio:

* Carrega `pautasAtuais` do `localStorage`;
* Solicita permissÃ£o do microfone via `navigator.mediaDevices`;
* Inicia o `MediaRecorder` com chunks de 1s;
* Dispara `setInterval` de 10s para:

  1. Parar o gravador;
  2. Enviar Ã¡udio para `/api/transcribe`;
  3. Receber texto transcrito;
  4. Enviar texto + pautas para `/api/analyze`;
  5. Atualizar status das subpautas (`completa = true`);
  6. Reiniciar a gravaÃ§Ã£o.

#### ğŸ”¹ Durante a gravaÃ§Ã£o:

* Exibe cronÃ´metro `â±ï¸ mm:ss`;
* Mostra transcriÃ§Ã£o cumulativa;
* Atualiza interface das pautas em tempo real:

  * Subpautas completas â†’ âœ…;
  * Pauta inteira â†’ fundo verde quando todas as subpautas estÃ£o completas.

#### ğŸ”¹ FinalizaÃ§Ã£o:

* UsuÃ¡rio clica â€œFinalizarâ€;
* GravaÃ§Ã£o Ã© encerrada e intervalos limpos;
* Envia `{ tipo, pautas, transcript }` para `/api/summarize`;
* Exibe tabela de resumo (ata) **abaixo da transcriÃ§Ã£o**.

---

## ğŸ“¡ Rotas de API

### `/api/transcribe/route.js`

**Entrada:**
`FormData` com `audio` (Blob, formato WebM)

**Processo:**

* Usa `openai.audio.transcriptions.create()`
* Modelo: `whisper-1` ou `gpt-4o-mini-transcribe`

**SaÃ­da:**

```json
{ "text": "trecho transcrito" }
```

---

### `/api/analyze/route.js`

**Entrada:**

```json
{
  "transcript": "texto atual",
  "pautas": [
    {
      "name": "HistÃ³rico Familiar",
      "subpautas": [{ "name": "RelaÃ§Ã£o com os pais" }]
    }
  ]
}
```

**Prompt interno:**
Solicita ao modelo para:

* Marcar `subpauta.completa = true` se o tema foi mencionado (mesmo com sinÃ´nimos);
* Retornar as pautas atualizadas.

**SaÃ­da esperada:**

```json
{
  "pautas": [
    {
      "name": "HistÃ³rico Familiar",
      "subpautas": [
        { "name": "RelaÃ§Ã£o com os pais", "completa": true }
      ]
    }
  ]
}
```

---

### `/api/summarize/route.js`

**Entrada:**

```json
{
  "tipo": "Entrevista de Acolhimento",
  "pautas": [...],
  "transcript": "texto completo"
}
```

**Prompt interno:**
Gera um resumo temÃ¡tico por pauta e subpauta, estruturado em JSON.

**SaÃ­da esperada:**

```json
{
  "ata": {
    "tipo": "Entrevista de Acolhimento",
    "duracao": "12min"
  },
  "resumo": [
    {
      "pauta": "HistÃ³rico Familiar",
      "subpautas": [
        {
          "titulo": "RelaÃ§Ã£o com os pais",
          "resumo": "O entrevistado relatou boa convivÃªncia..."
        }
      ]
    }
  ]
}
```

---

## ğŸ§® LÃ³gica de AtualizaÃ§Ã£o das Pautas

1. O transcript parcial (Ãºltimos 10s) Ã© enviado para anÃ¡lise;
2. O modelo avalia o texto e retorna subpautas marcadas com `completa: true`;
3. O frontend atualiza o estado de `pautas` com `setPautas(updated.pautas)`;
4. A renderizaÃ§Ã£o reativa do React pinta:

   * Subpautas com âœ…;
   * Pauta com fundo verde se todas as subpautas tiverem `completa = true`.

---

## ğŸ§¾ Resumo Final (RenderizaÃ§Ã£o)

Renderizado apenas se `resumoFinal.resumo` for array vÃ¡lido:

* Mostrado abaixo da transcriÃ§Ã£o;
* A transcriÃ§Ã£o continua visÃ­vel (nÃ£o substituÃ­da);
* Estrutura HTML:

  ```html
  <table>
    <thead>...</thead>
    <tbody>
      <tr>
        <td>Pauta</td>
        <td>Subpauta</td>
        <td>Resumo</td>
      </tr>
    </tbody>
  </table>
  ```

---

## ğŸ§° Logs e Debug

Durante a gravaÃ§Ã£o:

```bash
ğŸ¤ GravaÃ§Ã£o iniciada com reinÃ­cio automÃ¡tico a cada 10s
```

PossÃ­veis mensagens:

* `âš ï¸ NÃ£o foi possÃ­vel acessar o microfone` â†’ Falha de permissÃ£o;
* `"Sem texto detectado."` â†’ Whisper nÃ£o conseguiu extrair fala;
* `"Erro no ciclo de 10s:"` â†’ Falha em fetch da transcriÃ§Ã£o ou anÃ¡lise.

---

## ğŸ§¹ Limpeza e Encerramento

* Ao finalizar:

  * `mediaRecorder.stop()`
  * `track.stop()` em todos os canais de Ã¡udio;
  * `clearInterval(intervalRef.current)`
* Isso garante que o microfone seja liberado e a sessÃ£o encerrada com seguranÃ§a.

---

## ğŸ§­ Ciclo Completo da AplicaÃ§Ã£o

```mermaid
flowchart TD
A1[ğŸ  CriaÃ§Ã£o de Pautas] --> A2[ğŸ’¾ Salvar modelo no localStorage]
A2 --> A3[â–¶ï¸ Iniciar entrevista]
A3 --> B1[ğŸ™ï¸ GravaÃ§Ã£o e TranscriÃ§Ã£o]
B1 --> B2[ğŸ§  /api/transcribe - Ãudio â†’ Texto]
B2 --> B3[ğŸ“Š /api/analyze - Avalia pautas]
B3 --> B4[âœ… Atualiza UI - Subpautas completas]
B4 --> B5[ğŸ’¬ Mostra transcriÃ§Ã£o em tempo real]
B5 --> C1[ğŸŸ¥ Finalizar entrevista]
C1 --> C2[ğŸª¶ /api/summarize - Gera resumo final]
C2 --> C3[ğŸ“‹ Exibe tabela (Pauta/Subpauta/Resumo)]
C3 --> C4[ğŸ¯ Fim do processo]
```

---

## ğŸ” Dicas para Desenvolvimento

* Execute localmente:

  ```bash
  npm install
  npm run dev
  ```
* Teste APIs via Postman com exemplos JSON;
* Em ambiente Codespaces, garanta que o browser tenha permissÃ£o de microfone;
* Em produÃ§Ã£o (Vercel), os endpoints rodam em **Node serverless**, sem restriÃ§Ãµes de rede â€” ideal para as chamadas OpenAI.

---

## ğŸ§© PrÃ³ximas EvoluÃ§Ãµes

* [ ] Agrupar transcriÃ§Ãµes em buffer maior para contexto mais amplo na anÃ¡lise
* [ ] Cache de trechos jÃ¡ analisados
* [ ] Exportar ata em PDF
* [ ] Dashboard de entrevistas anteriores
* [ ] Filtros por status de pauta

---

**ManutenÃ§Ã£o:** Ivan LÃºcio Teles de Souza
ğŸ“§ `ivanltds@gmail.com` | ğŸ§  @ivanltds on GitHub
